----------------
Import MetaInfo:

username: None
django_settings: django_settings.hsv_settings
collection: Import HSV full 14-6-21
spacy_model: using local model
existing_annotations: data/viecpro_HSV_0.jsonl
path_df: data/3_HSV-angepasst-IMPORT.xlsx
path_hofstaat: data/Kürzel-Hofstaate-EX-ACC-2021-06-02.xlsx
path_aemter: data/Kürzel-Ämter-ACC-EX-2021-02-08.xlsx
path_abbreviations: data/EXCEL-ACCESS_Kürzel-Titel-Orden-2021-01-28.xlsx
logger_level: 20
collection_team: ['MRomberg', 'MKaiser', 'CStandhartinger']
use_stopvalues: False
is_test: False
sample_frame: using sample frame
without_testing: True
log_msg: None
----------------


get_model >>> Used config cfg class for model configuration
----------------
Using the local model: models/viecpro_ner_hsv_5-21/

NLP-pipeline:
	ner
	use_existing_annotations
	add_brackets
	rename_functions
	remove_names
	date_prepocissions
	create_chunks
----------------



--------- Start of row | 0 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> (?) [Mayr]
person_process_field_familienname >>> fam1: ?
person_process_field_familienname >>> fam2: <re.Match object; span=(2, 8), match='[Mayr]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kanzlist'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kanzlist'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = nan
helper_hsv_match_hofstaate >>> chunk Hofstaat = Dummy Hofstaat
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'Dummy Hofstaat', 'FUNKTION': ['Kanzlist'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = NÖ-LG / Kanzleiverwandte
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = NÖ-LG 
process_chunks >>> cD [], cF ['Kanzlist'], cH Dummy Hofstaat, CA NÖ-LG 
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: ?, Georg Ehrenreich>}
chunk_get_nm_hst >>> c_H = Dummy Hofstaat
chunk_process_amt_NEW >>> c_A in if c_A true: NÖ-LG 
chunk_process_amt_NEW >>> c_A was: NÖ-LG  and amt after matching with amt index is: NÖ-LG
chunk_process_amt_NEW >>>  Return value of inst2 = NÖ-LG (Dummy Hofstaat)
chunk_create_relations >>> create realtions called for c_F ['Kanzlist']

--------- Start of row | 1 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> (?)verl
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Registrant'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Registrant'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = nan
helper_hsv_match_hofstaate >>> chunk Hofstaat = Dummy Hofstaat
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'Dummy Hofstaat', 'FUNKTION': ['Registrant'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = NÖ-Expedition
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = NÖ-Expedition
process_chunks >>> cD [], cF ['Registrant'], cH Dummy Hofstaat, CA NÖ-Expedition
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: ?verl, Johann>}
chunk_get_nm_hst >>> c_H = Dummy Hofstaat
chunk_process_amt_NEW >>> c_A in if c_A true: NÖ-Expedition
chunk_process_amt_NEW >>> c_A was: NÖ-Expedition and amt after matching with amt index is: NÖ-Expedition
chunk_process_amt_NEW >>>  Return value of inst2 = NÖ-Expedition (Dummy Hofstaat)
chunk_create_relations >>> create realtions called for c_F ['Registrant']

--------- Start of row | 2 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> (Argumentin?)
person_process_field_familienname >>> fam1: (Argumentin?)
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 13), match='(Argumentin?)'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1699-01-01', 'bis 1704<1704-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Krankenwarterin'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1699-01-01', 'bis 1704<1704-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Krankenwarterin'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = AW
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: AW
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: AW
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1699-01-01', 'bis 1704<1704-06-30>'], 'HOFSTAAT': 'AW', 'FUNKTION': ['Krankenwarterin'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A =  / Frauenzimmer
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] =  
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD ['1699-01-01', 'bis 1704<1704-06-30>'], cF ['Krankenwarterin'], cH AW, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1699-01-01, new: 1699-01-01<1699-01-01>
helper_hsv_post_process_dates >>> inner date: <1704-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1704-06-30>
helper_hsv_post_process_dates >>> old: bis 1704<1704-06-30>, new: bis 1704<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1699-01-01<1699-01-01>
chunk_process_datum >>> rel, chunk edw: 1699-01-01<1699-01-01>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: (Argumentin?), Anna Susanna>, 'start_date_written': '1699-01-01<1699-01-01>', 'end_date_written': 'bis 1704<1704-06-30>'}
chunk_get_nm_hst >>> c_H = AW
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: AW (Kgin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (AW (Kgin.))
chunk_create_relations >>> create realtions called for c_F ['Krankenwarterin']

--------- Start of row | 3 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Bisegg]
person_process_field_familienname >>> fam1: [Bisegg]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 8), match='[Bisegg]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Guardadamas'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Guardadamas'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Guardadamas'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Guardadamas'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Bisegg], NN>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Guardadamas']

--------- Start of row | 4 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Brunnet]
person_process_field_familienname >>> fam1: [Brunnet]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 9), match='[Brunnet]'>
person_process_field_titel >>> t_tit = Don
person_process_field_titel >>> t_list = ['Don']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammerdiener'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Kammerdiener'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Brunnet], Petro>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammerdiener']

--------- Start of row | 5 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Glewelio]
person_process_field_familienname >>> fam1: [Glewelio]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 10), match='[Glewelio]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener', 'Garderobist'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener', 'Garderobist'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammerdiener', 'Garderobist'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Kammerdiener', 'Garderobist'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Glewelio], Adam>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammerdiener', 'Garderobist']

--------- Start of row | 6 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Gouisconi]
person_process_field_familienname >>> fam1: [Gouisconi]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 11), match='[Gouisconi]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdienerin'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdienerin'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammerdienerin'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = (Kammer- , Hoffräulein)
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = (Kammer- , Hoffräulein)
process_chunks >>> cD [], cF ['Kammerdienerin'], cH EM, CA (Kammer- , Hoffräulein)
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Gouisconi], Cäcilia>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: (Kammer- , Hoffräulein)
chunk_process_amt_NEW >>> c_A was: (Kammer- , Hoffräulein) and amt after matching with amt index is: (Kammer- , Hoffräulein)
chunk_process_amt_NEW >>>  Return value of inst2 = (Kammer- , Hoffräulein) (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammerdienerin']

--------- Start of row | 7 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Koch]
person_process_field_familienname >>> fam1: [Koch]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 6), match='[Koch]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammersekretär'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammersekretär'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammersekretär'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Kammersekretär'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Koch], Georg>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammersekretär']

--------- Start of row | 8 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Lengler]
person_process_field_familienname >>> fam1: [Lengler]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 9), match='[Lengler]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammertürhüter'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammertürhüter'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammertürhüter'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Kammertürhüter'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Lengler], Claudius>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammertürhüter']

--------- Start of row | 9 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Possio]
person_process_field_familienname >>> fam1: [Possio]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 8), match='[Possio]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammerdiener'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Kammerdiener'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Possio], Anton Ludwig >}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammerdiener']

--------- Start of row | 10 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Salzbrunner?]
person_process_field_familienname >>> fam1: [Salzbrunner?]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 14), match='[Salzbrunner?]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdienerin'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdienerin'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammerdienerin'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = (Kammer- , Hoffräulein)
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = (Kammer- , Hoffräulein)
process_chunks >>> cD [], cF ['Kammerdienerin'], cH EM, CA (Kammer- , Hoffräulein)
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Salzbrunner?], Maria Käterl >}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: (Kammer- , Hoffräulein)
chunk_process_amt_NEW >>> c_A was: (Kammer- , Hoffräulein) and amt after matching with amt index is: (Kammer- , Hoffräulein)
chunk_process_amt_NEW >>>  Return value of inst2 = (Kammer- , Hoffräulein) (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammerdienerin']

--------- Start of row | 11 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> [Tanner]
person_process_field_familienname >>> fam1: [Tanner]
person_process_field_familienname >>> fam2: <re.Match object; span=(0, 8), match='[Tanner]'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammertürhüter'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Kammertürhüter'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammertürhüter'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF ['Kammertürhüter'], cH EM, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: [Tanner], Georg>}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammertürhüter']

--------- Start of row | 12 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Aach (Ach, Arch)
person_process_field_familienname >>> fam1: Aach
person_process_field_familienname >>> fam2: <re.Match object; span=(5, 16), match='(Ach, Arch)'>
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1657-07-16', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer', 'Kämmerer, wirkl.'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1657-07-16', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer', 'Kämmerer, wirkl.'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1657-07-16', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer', 'Kämmerer, wirkl.'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1657-07-16', 'bis 1677<1677-06-30>'], cF ['Kämmerer', 'Kämmerer, wirkl.'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1657-07-16, new: 1657-07-16<1657-07-16>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1657-07-16<1657-07-16>
chunk_process_datum >>> rel, chunk edw: 1657-07-16<1657-07-16>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Aach, Prosper >, 'start_date_written': '1657-07-16<1657-07-16>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer', 'Kämmerer, wirkl.']

--------- Start of row | 13 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abel
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1663-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Rottmeister'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1663-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Rottmeister'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = LW
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: LW
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: LW
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1663-00-00'], 'HOFSTAAT': 'LW', 'FUNKTION': ['Rottmeister'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A =  / Trabantengarde
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] =  
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD ['1663-00-00'], cF ['Rottmeister'], cH LW, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1663-00-00, new: 1663-00-00<1663-06-30>
chunk_process_datum >>> rel, chunk sdw: 1663-00-00<1663-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abel, Johann>, 'start_date_written': '1663-00-00<1663-06-30>'}
chunk_get_nm_hst >>> c_H = LW
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: LW
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (LW)
chunk_create_relations >>> create realtions called for c_F ['Rottmeister']

--------- Start of row | 14 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abel
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1701-04-01'], 'HOFSTAAT': None, 'FUNKTION': ['Hartschier'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1701-04-01'], 'HOFSTAAT': None, 'FUNKTION': ['Hartschier'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = J
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: J
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: J
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1701-04-01'], 'HOFSTAAT': 'J', 'FUNKTION': ['Hartschier'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A =  / Hartschierenleibgarde
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] =  
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD ['1701-04-01'], cF ['Hartschier'], cH J, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1701-04-01, new: 1701-04-01<1701-04-01>
chunk_process_datum >>> rel, chunk sdw: 1701-04-01<1701-04-01>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abel, Johann Heinrich>, 'start_date_written': '1701-04-01<1701-04-01>'}
chunk_get_nm_hst >>> c_H = J
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: J1 (Ehzg.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (J1 (Ehzg.))
chunk_create_relations >>> create realtions called for c_F ['Hartschier']

--------- Start of row | 15 | -------------- 
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ); with: ) ;
replacer >>> r_fun: replaced ), with: ) ,
replacer >>> r_fun: replaced ); with: ) ;
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abele
person_process_field_titel >>> t_tit = Freiherr
person_process_field_titel >>> t_list = ['Freiherr']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc.ents at start of call = (Geh. Rat, Sekretär, 1672/73-00-00, Geh. Konferenzrat, 1672/73-00-00, Sekretär, 1672/73-00-00, 1680-00-00, Referendar, 1674/75-00-00, 1677-00-00, Rat, Hof-, 1675/76-00-00, Rat, ksl., 1675/76-00-00, 1677-00-00, Referendar, Konferenzen, 1675/76-00-00, Rat, ksl., Ö Expedition, Sekretär, Konferenzen, 1677-00-00, Hofrat, 1677-00-00, Hofkammerpräsident, 1681, 1683, Geh. Rat, 1685-11-01 / ab)
NLP COMPONENT >>> UseExistingAnnotations.py >>> compare docs
NLP COMPONENT >>> UseExistingAnnotations.py >>> THIS WAS LOGGED :15, Geh. Rat , Sekretär (1672/73-00-00) ; Geh. Konferenzrat (1672/73-00-00) ; Sekretär (1672/73-00-00 bis 1680-00-00) ; Referendar (1674/75-00-00 bis 1677-00-00) ; Rat, Hof- (1675/76-00-00) ; Rat, ksl. (1675/76-00-00 bis 1677-00-00) ; Referendar in allen Konferenzen (1675/76-00-00) ; Rat, ksl. der Ö Expedition; Sekretär in allen Konferenzen (1677-00-00) ; Hofrat (1677-00-00) ; Hofkammerpräsident (1681 bis 1683) , (Parvenue) ;Geh. Rat (1685-11-01 / ab dann 2.000 fl Gehalt, [{'start': 0, 'end': 8, 'token_start': 0, 'token_end': 2, 'label': 'FUNKTION'}, {'start': 11, 'end': 19, 'token_start': 4, 'token_end': 4, 'label': 'FUNKTION'}, {'start': 21, 'end': 34, 'token_start': 6, 'token_end': 12, 'label': 'DATUM'}, {'start': 37, 'end': 54, 'token_start': 15, 'token_end': 17, 'label': 'FUNKTION'}, {'start': 56, 'end': 69, 'token_start': 19, 'token_end': 25, 'label': 'DATUM'}, {'start': 72, 'end': 80, 'token_start': 28, 'token_end': 28, 'label': 'FUNKTION'}, {'start': 82, 'end': 95, 'token_start': 30, 'token_end': 36, 'label': 'DATUM'}, {'start': 100, 'end': 110, 'token_start': 38, 'token_end': 42, 'label': 'DATUM'}, {'start': 113, 'end': 123, 'token_start': 45, 'token_end': 45, 'label': 'FUNKTION'}, {'start': 125, 'end': 138, 'token_start': 47, 'token_end': 53, 'label': 'DATUM'}, {'start': 143, 'end': 153, 'token_start': 55, 'token_end': 59, 'label': 'DATUM'}, {'start': 156, 'end': 165, 'token_start': 62, 'token_end': 64, 'label': 'FUNKTION'}, {'start': 167, 'end': 180, 'token_start': 66, 'token_end': 72, 'label': 'DATUM'}, {'start': 183, 'end': 192, 'token_start': 75, 'token_end': 78, 'label': 'FUNKTION'}, {'start': 194, 'end': 207, 'token_start': 80, 'token_end': 86, 'label': 'DATUM'}, {'start': 212, 'end': 222, 'token_start': 88, 'token_end': 92, 'label': 'DATUM'}, {'start': 225, 'end': 235, 'token_start': 95, 'token_end': 95, 'label': 'FUNKTION'}, {'start': 245, 'end': 256, 'token_start': 98, 'token_end': 98, 'label': 'FUNKTION'}, {'start': 258, 'end': 271, 'token_start': 100, 'token_end': 106, 'label': 'DATUM'}, {'start': 274, 'end': 283, 'token_start': 109, 'token_end': 112, 'label': 'FUNKTION'}, {'start': 288, 'end': 300, 'token_start': 114, 'token_end': 115, 'label': 'AMT'}, {'start': 302, 'end': 310, 'token_start': 117, 'token_end': 117, 'label': 'FUNKTION'}, {'start': 333, 'end': 343, 'token_start': 122, 'token_end': 126, 'label': 'DATUM'}, {'start': 346, 'end': 352, 'token_start': 129, 'token_end': 129, 'label': 'FUNKTION'}, {'start': 354, 'end': 364, 'token_start': 131, 'token_end': 135, 'label': 'DATUM'}, {'start': 367, 'end': 385, 'token_start': 138, 'token_end': 138, 'label': 'FUNKTION'}, {'start': 387, 'end': 391, 'token_start': 140, 'token_end': 140, 'label': 'DATUM'}, {'start': 396, 'end': 400, 'token_start': 142, 'token_end': 142, 'label': 'DATUM'}, {'start': 404, 'end': 422, 'token_start': 146, 'token_end': 148, 'label': 'FUNKTION'}, {'start': 424, 'end': 439, 'token_start': 150, 'token_end': 156, 'label': 'DATUM'}]
NLP COMPONENT >>> UseExistingAnnotations.py >>> lst_ents = [Geh. Rat, Sekretär, 1672/73-00-00, Geh. Konferenzrat, 1672/73-00-00, Sekretär, 1672/73-00-00, 1680-00-00, Referendar, 1674/75-00-00, 1677-00-00, Rat, Hof-, 1675/76-00-00, Rat, ksl., 1675/76-00-00, 1677-00-00, Referendar, Konferenzen, 1675/76-00-00, Rat, ksl., Ö Expedition, Sekretär, 1677-00-00, Hofrat, 1677-00-00, Hofkammerpräsident, 1681, 1683, Parvenue) ;, . Rat (1685-11-]
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc.ents at end of call = (Geh. Rat, Sekretär, 1672/73-00-00, Geh. Konferenzrat, 1672/73-00-00, Sekretär, 1672/73-00-00, 1680-00-00, Referendar, 1674/75-00-00, 1677-00-00, Rat, Hof-, 1675/76-00-00, Rat, ksl., 1675/76-00-00, 1677-00-00, Referendar, Konferenzen, 1675/76-00-00, Rat, ksl., Ö Expedition, Sekretär, 1677-00-00, Hofrat, 1677-00-00, Hofkammerpräsident, 1681, 1683, Parvenue) ;, . Rat (1685-11-)
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = Ö Expedition
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(12) = [{'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat', 'Sekretär'], 'AMT': None}, {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Konferenzrat'], 'AMT': None}, {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1680<1680-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär'], 'AMT': None}, {'DATUM': ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Referendar'], 'AMT': None}, {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Hofrat'], 'AMT': None}, {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Rat, ksl.'], 'AMT': None}, {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Referendar', 'Konferenzen'], 'AMT': None}, {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Rat, ksl.'], 'AMT': 'Ö Expedition'}, {'DATUM': ['1677-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär'], 'AMT': None}, {'DATUM': ['1677-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Hofrat'], 'AMT': None}, {'DATUM': ['1681', 'bis 1683<1683-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Hofkammerpräsident'], 'AMT': None}, {'DATUM': ['. Rat (1685-11-'], 'HOFSTAAT': None, 'FUNKTION': ['Parvenue) ;'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat', 'Sekretär'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	1: chunk: {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Konferenzrat'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	2: chunk: {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1680<1680-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	3: chunk: {'DATUM': ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Referendar'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	4: chunk: {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Hofrat'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	5: chunk: {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Rat, ksl.'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	6: chunk: {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>'], 'HOFSTAAT': None, 'FUNKTION': ['Referendar', 'Konferenzen'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	7: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': ['Rat, ksl.'], 'AMT': 'Ö Expedition'}
NLP COMPONENT >>> CreateChunks.py >>> 	8: chunk: {'DATUM': ['1677-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	9: chunk: {'DATUM': ['1677-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Hofrat'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	10: chunk: {'DATUM': ['1681', 'bis 1683<1683-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Hofkammerpräsident'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	11: chunk: {'DATUM': ['. Rat (1685-11-'], 'HOFSTAAT': None, 'FUNKTION': ['Parvenue) ;'], 'AMT': None}
process_chunks >>> len_doc_chunks: 12, len Ämter-Spalte: 6
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Geh. Rat', 'Sekretär'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Geh. Konferenzrat'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1680<1680-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Sekretär'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Referendar'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Hofrat'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Rat, ksl.'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Referendar', 'Konferenzen'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'L', 'FUNKTION': ['Rat, ksl.'], 'AMT': 'Ö Expedition'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1677-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Sekretär'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1677-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Hofrat'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1681', 'bis 1683<1683-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Hofkammerpräsident'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['. Rat (1685-11-'], 'HOFSTAAT': 'L', 'FUNKTION': ['Parvenue) ;'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = GK; Ö-HKz; GR / Sekretarien; HK; Ö Expedition; 
process_chunks >>> cD ['1672/73-00-00<1672-06-30 - 73-00-00>'], cF ['Geh. Rat', 'Sekretär'], cH L, CA GK
helper_hsv_post_process_dates >>> inner date: <1672-06-30 - 73-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1672-06-30 - 73-06-30>
helper_hsv_post_process_dates >>> old: 1672/73-00-00<1672-06-30 - 73-00-00>, new: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>> rel, chunk sdw: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1672/73-00-00<1672-06-30 - 73-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: GK
chunk_process_amt_NEW >>> c_A was: GK and amt after matching with amt index is: GK
chunk_process_amt_NEW >>>  Return value of inst2 = GK (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Geh. Rat', 'Sekretär']
process_chunks >>> cD ['1672/73-00-00<1672-06-30 - 73-00-00>'], cF ['Geh. Konferenzrat'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> inner date: <1672-06-30 - 73-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1672-06-30 - 73-06-30>
helper_hsv_post_process_dates >>> old: 1672/73-00-00<1672-06-30 - 73-00-00>, new: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>> rel, chunk sdw: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1672/73-00-00<1672-06-30 - 73-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Geh. Konferenzrat']
process_chunks >>> cD ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1680<1680-06-30>'], cF ['Sekretär'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> inner date: <1672-06-30 - 73-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1672-06-30 - 73-06-30>
helper_hsv_post_process_dates >>> old: 1672/73-00-00<1672-06-30 - 73-00-00>, new: 1672/73-00-00<1672-06-30 - 73-06-30>
helper_hsv_post_process_dates >>> inner date: <1680-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1680-06-30>
helper_hsv_post_process_dates >>> old: bis 1680<1680-06-30>, new: bis 1680<1680-06-30>
chunk_process_datum >>> rel, chunk sdw: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>> rel, chunk edw: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1672/73-00-00<1672-06-30 - 73-06-30>', 'end_date_written': 'bis 1680<1680-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Sekretär']
process_chunks >>> cD ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], cF ['Referendar'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> inner date: <1674-06-30 - 75-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1674-06-30 - 75-06-30>
helper_hsv_post_process_dates >>> old: 1674/75-00-00<1674-06-30 - 75-00-00>, new: 1674/75-00-00<1674-06-30 - 75-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1674/75-00-00<1674-06-30 - 75-06-30>
chunk_process_datum >>> rel, chunk edw: 1674/75-00-00<1674-06-30 - 75-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1674/75-00-00<1674-06-30 - 75-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Referendar']
process_chunks >>> cD ['1675/76-00-00<1675-06-30 - 76-00-00>'], cF ['Hofrat'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> inner date: <1675-06-30 - 76-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> old: 1675/76-00-00<1675-06-30 - 76-00-00>, new: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>> rel, chunk sdw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1675/76-00-00<1675-06-30 - 76-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Hofrat']
process_chunks >>> cD ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], cF ['Rat, ksl.'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> inner date: <1675-06-30 - 76-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> old: 1675/76-00-00<1675-06-30 - 76-00-00>, new: 1675/76-00-00<1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>> rel, chunk edw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1675/76-00-00<1675-06-30 - 76-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Rat, ksl.']
process_chunks >>> cD ['1675/76-00-00<1675-06-30 - 76-00-00>'], cF ['Referendar', 'Konferenzen'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> inner date: <1675-06-30 - 76-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> old: 1675/76-00-00<1675-06-30 - 76-00-00>, new: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>> rel, chunk sdw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1675/76-00-00<1675-06-30 - 76-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Referendar', 'Konferenzen']
process_chunks >>> cD [], cF ['Rat, ksl.'], cH L, CA Ö Expedition
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Ö Expedition
chunk_process_amt_NEW >>> c_A was: Ö Expedition and amt after matching with amt index is: Ö Expedition
chunk_process_amt_NEW >>>  Return value of inst2 = Ö Expedition (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Rat, ksl.']
process_chunks >>> cD ['1677-00-00'], cF ['Sekretär'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1677-00-00, new: 1677-00-00<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1677-00-00<1677-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1677-00-00<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Sekretär']
process_chunks >>> cD ['1677-00-00'], cF ['Hofrat'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1677-00-00, new: 1677-00-00<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1677-00-00<1677-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1677-00-00<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Hofrat']
process_chunks >>> cD ['1681', 'bis 1683<1683-06-30>'], cF ['Hofkammerpräsident'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1681, new: 1681<1681>
helper_hsv_post_process_dates >>> inner date: <1683-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1683-06-30>
helper_hsv_post_process_dates >>> old: bis 1683<1683-06-30>, new: bis 1683<1683-06-30>
chunk_process_datum >>> rel, chunk sdw: 1681<1681>
chunk_process_datum >>> rel, chunk edw: 1681<1681>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '1681<1681>', 'end_date_written': 'bis 1683<1683-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Hofkammerpräsident']
parse_iso_date >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' 1681<1681> ' due to error ('Invalid iso date: ', '1681'): 
process_chunks >>> cD ['. Rat (1685-11-'], cF ['Parvenue) ;'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> old: . Rat (1685-11-, new: . Rat (1685-11-
chunk_process_datum >>> rel, chunk sdw: . Rat (1685-11-
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Christoph>, 'start_date_written': '. Rat (1685-11-'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Parvenue) ;']
parse_date_range_individual >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' .rat(1685-11- ' due to error Could not interpret date.: 

--------- Start of row | 16 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abele
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1677-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1677-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1677-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Sekretär'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = HKR  /  Sekretarien
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = HKR  
process_chunks >>> cD ['1677-00-00'], cF ['Sekretär'], cH L, CA HKR  
helper_hsv_post_process_dates >>> old: 1677-00-00, new: 1677-00-00<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1677-00-00<1677-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele, Ferdinand>, 'start_date_written': '1677-00-00<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: HKR  
chunk_process_amt_NEW >>> c_A was: HKR   and amt after matching with amt index is: HKR
chunk_process_amt_NEW >>>  Return value of inst2 = HKR (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Sekretär']

--------- Start of row | 17 | -------------- 
replacer >>> r_fun: replaced ,g with: , g
replacer >>> r_fun: replaced ); with: ) ;
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abele von , zu Lilienberg
person_process_field_titel >>> t_tit = Freiherr
person_process_field_titel >>> t_list = ['Freiherr']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(2) = [{'DATUM': ['1657-00-00', '1665-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär', 'Beamter'], 'AMT': None}, {'DATUM': ['1681-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Hofkammerpräsident'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1657-00-00', '1665-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sekretär', 'Beamter'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	1: chunk: {'DATUM': ['1681-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Hofkammerpräsident'], 'AMT': None}
process_chunks >>> len_doc_chunks: 2, len Ämter-Spalte: 2
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1657-00-00', '1665-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Sekretär', 'Beamter'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1681-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Hofkammerpräsident'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = HK; Ö-HKz
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = HK
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] =  Ö-HKz
process_chunks >>> cD ['1657-00-00', '1665-00-00'], cF ['Sekretär', 'Beamter'], cH L, CA HK
helper_hsv_post_process_dates >>> old: 1657-00-00, new: 1657-00-00<1657-06-30>
helper_hsv_post_process_dates >>> old: 1665-00-00, new: 1665-00-00<1665-06-30>
chunk_process_datum >>> rel, chunk sdw: 1657-00-00<1657-06-30>
chunk_process_datum >>> rel, chunk edw: 1657-00-00<1657-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele von , zu Lilienberg, Christoph Ignaz>, 'start_date_written': '1657-00-00<1657-06-30>', 'end_date_written': '1665-00-00<1665-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: HK
chunk_process_amt_NEW >>> c_A was: HK and amt after matching with amt index is: HK
chunk_process_amt_NEW >>>  Return value of inst2 = HK (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Sekretär', 'Beamter']
process_chunks >>> cD ['1681-00-00'], cF ['Hofkammerpräsident'], cH L, CA  Ö-HKz
helper_hsv_post_process_dates >>> old: 1681-00-00, new: 1681-00-00<1681-06-30>
chunk_process_datum >>> rel, chunk sdw: 1681-00-00<1681-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abele von , zu Lilienberg, Christoph Ignaz>, 'start_date_written': '1681-00-00<1681-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true:  Ö-HKz
chunk_process_amt_NEW >>> c_A was:  Ö-HKz and amt after matching with amt index is: Ö-HKz
chunk_process_amt_NEW >>>  Return value of inst2 = Ö-HKz (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Hofkammerpräsident']

--------- Start of row | 18 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abend
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Instrumentalist'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Instrumentalist'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Instrumentalist'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OMeA / Hofmusikanten
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OMeA 
process_chunks >>> cD ['1704-00-00'], cF ['Instrumentalist'], cH L, CA OMeA 
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abend, Andreas>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OMeA 
chunk_process_amt_NEW >>> c_A was: OMeA  and amt after matching with amt index is: OMeA
chunk_process_amt_NEW >>>  Return value of inst2 = OMeA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Instrumentalist']

--------- Start of row | 19 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abensberg-Traun
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = VodM.
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Oberkommissar'], 'AMT': 'VodM.'}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Oberkommissar'], 'AMT': 'VodM.'}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = nan
helper_hsv_match_hofstaate >>> chunk Hofstaat = Dummy Hofstaat
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'Dummy Hofstaat', 'FUNKTION': ['Oberkommissar'], 'AMT': 'VodM.'}
helper_hsv_match_amt_with_funct >>> r_A = NÖ Landschaftskommissariat
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = VodM.
process_chunks >>> cD ['1704-00-00'], cF ['Oberkommissar'], cH Dummy Hofstaat, CA VodM.
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Franz Anton>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = Dummy Hofstaat
chunk_process_amt_NEW >>> c_A in if c_A true: VodM.
chunk_process_amt_NEW >>> c_A was: VodM. and amt after matching with amt index is: VodM.
chunk_process_amt_NEW >>>  Return value of inst2 = VodM. (Dummy Hofstaat)
chunk_create_relations >>> create realtions called for c_F ['Oberkommissar']

--------- Start of row | 20 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abensberg-Traun (Abensperg-Traun, Abensperg , Traun)
person_process_field_familienname >>> fam1: Abensberg-Traun
person_process_field_familienname >>> fam2: <re.Match object; span=(16, 52), match='(Abensperg-Traun, Abensperg , Traun)'>
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc.ents at start of call = (Landmarschall, 1658-09-30 / 1698-00-00, Kämmerer, 1669-03-26 / 1701-00-00 / 1704-00-00, OKäA, Geh. Rat, ksl., Landmarschall, Ö, 1698-00-00, Geh. Rat, 1701-00-00 / 1704-00-00, GR, Landmarschall, Generallandoberst, NÖ, 1701-00-00, NÖ-R, Geh. Konferenzrat, 1701-00-00 / 1704-00-00, GK, Generallandoberst, 1701-00-00, NÖ, Generallandoberst, 1704-00-00, Ö-udE, Landmarschall, Generallandoberst, Ö-udE., 1704-00-00, NÖ-LG)
NLP COMPONENT >>> UseExistingAnnotations.py >>> compare docs
NLP COMPONENT >>> UseExistingAnnotations.py >>> THIS WAS LOGGED :20, Landmarschall (1658-09-30 / 1698-00-00) \ Empfang des Kaisers vor Wien \ NÖ; Kämmerer (1669-03-26 / 1701-00-00 / 1704-00-00) \ Eid \ OKäA; Geh. Rat, ksl., Landmarschall in Ö (1698-00-00) \ Liste RGV; Geh. Rat (1701-00-00 / 1704-00-00) \ GR; Landmarschall , Generallandoberst NÖ (1701-00-00) \ NÖ-R; Geh. Konferenzrat (1701-00-00 / 1704-00-00) GK; Generallandoberst (1701-00-00) \ NÖ; Generallandoberst (1704-00-00) \ Ö-udE; Landmarschall , Generallandoberst in Ö-udE. (1704-00-00) \ NÖ-LG, [{'start': 0, 'end': 13, 'token_start': 0, 'token_end': 0, 'label': 'FUNKTION'}, {'start': 15, 'end': 38, 'token_start': 2, 'token_end': 12, 'label': 'DATUM'}, {'start': 77, 'end': 85, 'token_start': 23, 'token_end': 23, 'label': 'FUNKTION'}, {'start': 87, 'end': 123, 'token_start': 25, 'token_end': 41, 'label': 'DATUM'}, {'start': 133, 'end': 137, 'token_start': 46, 'token_end': 46, 'label': 'AMT'}, {'start': 139, 'end': 147, 'token_start': 48, 'token_end': 50, 'label': 'FUNKTION'}, {'start': 155, 'end': 168, 'token_start': 55, 'token_end': 55, 'label': 'FUNKTION'}, {'start': 172, 'end': 173, 'token_start': 57, 'token_end': 57, 'label': 'AMT'}, {'start': 175, 'end': 185, 'token_start': 59, 'token_end': 63, 'label': 'DATUM'}, {'start': 200, 'end': 208, 'token_start': 69, 'token_end': 71, 'label': 'FUNKTION'}, {'start': 210, 'end': 233, 'token_start': 73, 'token_end': 83, 'label': 'DATUM'}, {'start': 237, 'end': 239, 'token_start': 86, 'token_end': 86, 'label': 'FUNKTION'}, {'start': 241, 'end': 254, 'token_start': 88, 'token_end': 88, 'label': 'FUNKTION'}, {'start': 257, 'end': 274, 'token_start': 90, 'token_end': 90, 'label': 'FUNKTION'}, {'start': 275, 'end': 277, 'token_start': 91, 'token_end': 91, 'label': 'AMT'}, {'start': 279, 'end': 289, 'token_start': 93, 'token_end': 97, 'label': 'DATUM'}, {'start': 293, 'end': 297, 'token_start': 100, 'token_end': 100, 'label': 'AMT'}, {'start': 299, 'end': 316, 'token_start': 102, 'token_end': 104, 'label': 'FUNKTION'}, {'start': 318, 'end': 341, 'token_start': 106, 'token_end': 116, 'label': 'DATUM'}, {'start': 343, 'end': 345, 'token_start': 118, 'token_end': 118, 'label': 'AMT'}, {'start': 347, 'end': 364, 'token_start': 120, 'token_end': 120, 'label': 'FUNKTION'}, {'start': 366, 'end': 376, 'token_start': 122, 'token_end': 126, 'label': 'DATUM'}, {'start': 380, 'end': 382, 'token_start': 129, 'token_end': 129, 'label': 'AMT'}, {'start': 384, 'end': 401, 'token_start': 131, 'token_end': 131, 'label': 'FUNKTION'}, {'start': 403, 'end': 413, 'token_start': 133, 'token_end': 137, 'label': 'DATUM'}, {'start': 417, 'end': 422, 'token_start': 140, 'token_end': 140, 'label': 'AMT'}, {'start': 424, 'end': 437, 'token_start': 142, 'token_end': 142, 'label': 'FUNKTION'}, {'start': 440, 'end': 457, 'token_start': 144, 'token_end': 144, 'label': 'FUNKTION'}, {'start': 461, 'end': 467, 'token_start': 146, 'token_end': 146, 'label': 'AMT'}, {'start': 469, 'end': 479, 'token_start': 148, 'token_end': 152, 'label': 'DATUM'}, {'start': 483, 'end': 488, 'token_start': 155, 'token_end': 155, 'label': 'AMT'}]
NLP COMPONENT >>> UseExistingAnnotations.py >>> lst_ents = [Landmarschall, 1658-09-30 / 1698-00-00, Kämmerer, 1669-03-26 / 1701-00-00 / 1704-00-00, OKäA, Geh. Rat, Landmarschall, Ö, 1698-00-00, Geh. Rat, 1701-00-00 / 1704-00-00, GR, Landmarschall, Generallandoberst, NÖ, 1701-00-00, NÖ-R, Geh. Konferenzrat, 1701-00-00 / 1704-00-00, GK, Generallandoberst, 1701-00-00, NÖ, Generallandoberst, 1704-00-00, Ö-udE, Landmarschall, Generallandoberst, Ö-udE., 1704-00-00, NÖ-LG]
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc.ents at end of call = (Landmarschall, 1658-09-30 / 1698-00-00, Kämmerer, 1669-03-26 / 1701-00-00 / 1704-00-00, OKäA, Geh. Rat, Landmarschall, Ö, 1698-00-00, Geh. Rat, 1701-00-00 / 1704-00-00, GR, Landmarschall, Generallandoberst, NÖ, 1701-00-00, NÖ-R, Geh. Konferenzrat, 1701-00-00 / 1704-00-00, GK, Generallandoberst, 1701-00-00, NÖ, Generallandoberst, 1704-00-00, Ö-udE, Landmarschall, Generallandoberst, Ö-udE., 1704-00-00, NÖ-LG)
NLP COMPONENT >>> RenameFunctions.py >>> removing Ö from ents
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = OKäA
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = NÖ
NLP COMPONENT >>> CreateChunks.py >>> In else clause of chunks, chunk = {'DATUM': ['1701-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'NÖ'}
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = GK
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = NÖ
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = Ö-udE
NLP COMPONENT >>> CreateChunks.py >>> Chunk AMT = Ö-udE.
NLP COMPONENT >>> CreateChunks.py >>> In else clause of chunks, chunk = {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'Ö-udE.'}
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(11) = [{'DATUM': ['1658-09-30 / 1698-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall'], 'AMT': None}, {'DATUM': ['1669-03-26 / 1701-00-00 / 1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': 'OKäA'}, {'DATUM': ['1698-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat', 'Landmarschall'], 'AMT': None}, {'DATUM': ['1701-00-00 / 1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat', 'GR'], 'AMT': None}, {'DATUM': ['1701-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'NÖ'}, {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}, {'DATUM': ['1701-00-00 / 1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Konferenzrat'], 'AMT': 'GK'}, {'DATUM': ['1701-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Generallandoberst'], 'AMT': 'NÖ'}, {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Generallandoberst'], 'AMT': 'Ö-udE'}, {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'Ö-udE.'}, {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1658-09-30 / 1698-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	1: chunk: {'DATUM': ['1669-03-26 / 1701-00-00 / 1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': 'OKäA'}
NLP COMPONENT >>> CreateChunks.py >>> 	2: chunk: {'DATUM': ['1698-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat', 'Landmarschall'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	3: chunk: {'DATUM': ['1701-00-00 / 1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat', 'GR'], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	4: chunk: {'DATUM': ['1701-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'NÖ'}
NLP COMPONENT >>> CreateChunks.py >>> 	5: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}
NLP COMPONENT >>> CreateChunks.py >>> 	6: chunk: {'DATUM': ['1701-00-00 / 1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Konferenzrat'], 'AMT': 'GK'}
NLP COMPONENT >>> CreateChunks.py >>> 	7: chunk: {'DATUM': ['1701-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Generallandoberst'], 'AMT': 'NÖ'}
NLP COMPONENT >>> CreateChunks.py >>> 	8: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Generallandoberst'], 'AMT': 'Ö-udE'}
NLP COMPONENT >>> CreateChunks.py >>> 	9: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'Ö-udE.'}
NLP COMPONENT >>> CreateChunks.py >>> 	10: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}
process_chunks >>> len_doc_chunks: 11, len Ämter-Spalte: 8
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1658-09-30 / 1698-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Landmarschall'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1669-03-26 / 1701-00-00 / 1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': 'OKäA'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1698-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Geh. Rat', 'Landmarschall'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1701-00-00 / 1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Geh. Rat', 'GR'], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1701-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'NÖ'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'L', 'FUNKTION': [], 'AMT': None}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1701-00-00 / 1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Geh. Konferenzrat'], 'AMT': 'GK'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1701-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Generallandoberst'], 'AMT': 'NÖ'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Generallandoberst'], 'AMT': 'Ö-udE'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Landmarschall', 'Generallandoberst'], 'AMT': 'Ö-udE.'}
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'L', 'FUNKTION': [], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = GR; KR; NÖ; NÖ-LG; NÖ-R; OKäA; Ö-udE.;
process_chunks >>> cD ['1658-09-30 / 1698-00-00'], cF ['Landmarschall'], cH L, CA GR
helper_hsv_post_process_dates >>> old: 1658-09-30 / 1698-00-00, new: 1658-09-30 / 1698-00-00
chunk_process_datum >>> rel, chunk sdw: 1658-09-30 / 1698-00-00
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1658-09-30 / 1698-00-00'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: GR
chunk_process_amt_NEW >>> c_A was: GR and amt after matching with amt index is: GR
chunk_process_amt_NEW >>>  Return value of inst2 = GR (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Landmarschall']
parse_date_range_individual >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' 1658-09-30/1698-00-00 ' due to error Could not interpret date.: 
process_chunks >>> cD ['1669-03-26 / 1701-00-00 / 1704-00-00'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1669-03-26 / 1701-00-00 / 1704-00-00, new: 1669-03-26 / 1701-00-00 / 1704-00-00
chunk_process_datum >>> rel, chunk sdw: 1669-03-26 / 1701-00-00 / 1704-00-00
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1669-03-26 / 1701-00-00 / 1704-00-00'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']
parse_date_range_individual >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' 1669-03-26/1701-00-00/1704-00-00 ' due to error Could not interpret date.: 
process_chunks >>> cD ['1698-00-00'], cF ['Geh. Rat', 'Landmarschall'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1698-00-00, new: 1698-00-00<1698-06-30>
chunk_process_datum >>> rel, chunk sdw: 1698-00-00<1698-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1698-00-00<1698-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Geh. Rat', 'Landmarschall']
process_chunks >>> cD ['1701-00-00 / 1704-00-00'], cF ['Geh. Rat', 'GR'], cH L, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1701-00-00 / 1704-00-00, new: 1701-00-00 / 1704-00-00
chunk_process_datum >>> rel, chunk sdw: 1701-00-00 / 1704-00-00
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1701-00-00 / 1704-00-00'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Geh. Rat', 'GR']
parse_date_range_individual >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' 1701-00-00/1704-00-00 ' due to error Could not interpret date.: 
parse_date_range_individual >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' 1701-00-00/1704-00-00 ' due to error Could not interpret date.: 
process_chunks >>> cD ['1701-00-00'], cF ['Landmarschall', 'Generallandoberst'], cH L, CA NÖ
helper_hsv_post_process_dates >>> old: 1701-00-00, new: 1701-00-00<1701-06-30>
chunk_process_datum >>> rel, chunk sdw: 1701-00-00<1701-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1701-00-00<1701-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: NÖ
chunk_process_amt_NEW >>> c_A was: NÖ and amt after matching with amt index is: NÖ
chunk_process_amt_NEW >>>  Return value of inst2 = NÖ (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Landmarschall', 'Generallandoberst']
process_chunks >>> cD [], cF [], cH L, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F []
process_chunks >>> cD ['1701-00-00 / 1704-00-00'], cF ['Geh. Konferenzrat'], cH L, CA GK
helper_hsv_post_process_dates >>> old: 1701-00-00 / 1704-00-00, new: 1701-00-00 / 1704-00-00
chunk_process_datum >>> rel, chunk sdw: 1701-00-00 / 1704-00-00
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1701-00-00 / 1704-00-00'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: GK
chunk_process_amt_NEW >>> c_A was: GK and amt after matching with amt index is: GK
chunk_process_amt_NEW >>>  Return value of inst2 = GK (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Geh. Konferenzrat']
parse_date_range_individual >>> APIS: Could not interpret date: <class 'ValueError'>
parse_date >>>  APIS: Could not parse date: ' 1701-00-00/1704-00-00 ' due to error Could not interpret date.: 
process_chunks >>> cD ['1701-00-00'], cF ['Generallandoberst'], cH L, CA NÖ
helper_hsv_post_process_dates >>> old: 1701-00-00, new: 1701-00-00<1701-06-30>
chunk_process_datum >>> rel, chunk sdw: 1701-00-00<1701-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1701-00-00<1701-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: NÖ
chunk_process_amt_NEW >>> c_A was: NÖ and amt after matching with amt index is: NÖ
chunk_process_amt_NEW >>>  Return value of inst2 = NÖ (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Generallandoberst']
process_chunks >>> cD ['1704-00-00'], cF ['Generallandoberst'], cH L, CA Ö-udE
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Ö-udE
chunk_process_amt_NEW >>> c_A was: Ö-udE and amt after matching with amt index is: Ö-udE
chunk_process_amt_NEW >>>  Return value of inst2 = Ö-udE (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Generallandoberst']
process_chunks >>> cD ['1704-00-00'], cF ['Landmarschall', 'Generallandoberst'], cH L, CA Ö-udE.
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Ö-udE.
chunk_process_amt_NEW >>> c_A was: Ö-udE. and amt after matching with amt index is: Ö-udE.
chunk_process_amt_NEW >>>  Return value of inst2 = Ö-udE. (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Landmarschall', 'Generallandoberst']
process_chunks >>> cD [], cF [], cH L, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensberg-Traun, Otto Ehrenreich>}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F []

--------- Start of row | 21 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abensperg , Traun
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1666-10-10'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1666-10-10'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1666-10-10'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1666-10-10'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1666-10-10, new: 1666-10-10<1666-10-10>
chunk_process_datum >>> rel, chunk sdw: 1666-10-10<1666-10-10>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensperg , Traun, Ernst Ferdinand>, 'start_date_written': '1666-10-10<1666-10-10>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 22 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abensperg , Traun
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1666-09-03'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1666-09-03'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1666-09-03'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1666-09-03'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1666-09-03, new: 1666-09-03<1666-09-03>
chunk_process_datum >>> rel, chunk sdw: 1666-09-03<1666-09-03>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensperg , Traun, Johann Wilhelm>, 'start_date_written': '1666-09-03<1666-09-03>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 23 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abensperg-Traun
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1657-06-19'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1657-06-19'], 'HOFSTAAT': None, 'FUNKTION': ['Geh. Rat'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1657-06-19'], 'HOFSTAAT': 'L', 'FUNKTION': ['Geh. Rat'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = GR
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = GR
process_chunks >>> cD ['1657-06-19'], cF ['Geh. Rat'], cH L, CA GR
helper_hsv_post_process_dates >>> old: 1657-06-19, new: 1657-06-19<1657-06-19>
chunk_process_datum >>> rel, chunk sdw: 1657-06-19<1657-06-19>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abensperg-Traun, Ernst>, 'start_date_written': '1657-06-19<1657-06-19>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: GR
chunk_process_amt_NEW >>> c_A was: GR and amt after matching with amt index is: GR
chunk_process_amt_NEW >>>  Return value of inst2 = GR (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Geh. Rat']

--------- Start of row | 24 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Ableitner (Ableutner)
person_process_field_familienname >>> fam1: Ableitner
person_process_field_familienname >>> fam2: <re.Match object; span=(10, 21), match='(Ableutner)'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Kanzlist'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Kanzlist'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kanzlist'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = HK / Kanzlisten
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = HK 
process_chunks >>> cD ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], cF ['Kanzlist'], cH L, CA HK 
helper_hsv_post_process_dates >>> inner date: <1675-06-30 - 76-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> old: 1675/76-00-00<1675-06-30 - 76-00-00>, new: 1675/76-00-00<1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>> rel, chunk edw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Ableitner, Ferdinand>, 'start_date_written': '1675/76-00-00<1675-06-30 - 76-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: HK 
chunk_process_amt_NEW >>> c_A was: HK  and amt after matching with amt index is: HK
chunk_process_amt_NEW >>>  Return value of inst2 = HK (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kanzlist']

--------- Start of row | 25 | -------------- 
replacer >>> r_fun: replaced ), with: ) ,
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Abt
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1694-10-01', '1701-03-31'], 'HOFSTAAT': None, 'FUNKTION': ['Hartschier'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1694-10-01', '1701-03-31'], 'HOFSTAAT': None, 'FUNKTION': ['Hartschier'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = J
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: J
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: J
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1694-10-01', '1701-03-31'], 'HOFSTAAT': 'J', 'FUNKTION': ['Hartschier'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A =  / Hartschierenleibgarde
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] =  
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD ['1694-10-01', '1701-03-31'], cF ['Hartschier'], cH J, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1694-10-01, new: 1694-10-01<1694-10-01>
helper_hsv_post_process_dates >>> old: 1701-03-31, new: 1701-03-31<1701-03-31>
chunk_process_datum >>> rel, chunk sdw: 1694-10-01<1694-10-01>
chunk_process_datum >>> rel, chunk edw: 1694-10-01<1694-10-01>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Abt, Dionisius>, 'start_date_written': '1694-10-01<1694-10-01>', 'end_date_written': '1701-03-31<1701-03-31>'}
chunk_get_nm_hst >>> c_H = J
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: J1 (Ehzg.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (J1 (Ehzg.))
chunk_create_relations >>> create realtions called for c_F ['Hartschier']

--------- Start of row | 26 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Achat (Achaz, Nachod)
person_process_field_familienname >>> fam1: Achat
person_process_field_familienname >>> fam2: <re.Match object; span=(6, 21), match='(Achaz, Nachod)'>
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1674/75-00-00<1674-06-30 - 75-00-00>', 'bis 1677<1677-06-30>'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> inner date: <1674-06-30 - 75-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1674-06-30 - 75-06-30>
helper_hsv_post_process_dates >>> old: 1674/75-00-00<1674-06-30 - 75-00-00>, new: 1674/75-00-00<1674-06-30 - 75-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1674/75-00-00<1674-06-30 - 75-06-30>
chunk_process_datum >>> rel, chunk edw: 1674/75-00-00<1674-06-30 - 75-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Achat, Ferdinand Leopold>, 'start_date_written': '1674/75-00-00<1674-06-30 - 75-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 27 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Achendorffer
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = J
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: J
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: J
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'J', 'FUNKTION': [], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OMeA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OMeA
process_chunks >>> cD ['1704-00-00'], cF [], cH J, CA OMeA
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Achendorffer, Jakob>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = J
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: J1 (Ehzg.)
chunk_process_amt_NEW >>> c_A in if c_A true: OMeA
chunk_process_amt_NEW >>> c_A was: OMeA and amt after matching with amt index is: OMeA
chunk_process_amt_NEW >>>  Return value of inst2 = OMeA (J1 (Ehzg.))
chunk_create_relations >>> create realtions called for c_F []

--------- Start of row | 28 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Achimis/Attems?
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1704-00-00'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Achimis/Attems?, Ignaz>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 29 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adalbert (Adelberth, Adelwerth, Adlberth, Adolbert, Adolberth)
person_process_field_familienname >>> fam1: Adalbert
person_process_field_familienname >>> fam2: <re.Match object; span=(9, 62), match='(Adelberth, Adelwerth, Adlberth, Adolbert, Adolbe>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1674-00-00', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Konzipist'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1674-00-00', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Konzipist'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1674-00-00', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Konzipist'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = NÖ-R / Konzipisten
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = NÖ-R 
process_chunks >>> cD ['1674-00-00', 'bis 1677<1677-06-30>'], cF ['Konzipist'], cH L, CA NÖ-R 
helper_hsv_post_process_dates >>> old: 1674-00-00, new: 1674-00-00<1674-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1674-00-00<1674-06-30>
chunk_process_datum >>> rel, chunk edw: 1674-00-00<1674-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adalbert, Johann>, 'start_date_written': '1674-00-00<1674-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: NÖ-R 
chunk_process_amt_NEW >>> c_A was: NÖ-R  and amt after matching with amt index is: NÖ-R
chunk_process_amt_NEW >>>  Return value of inst2 = NÖ-R (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Konzipist']

--------- Start of row | 30 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adalbert (Adelberth)
person_process_field_familienname >>> fam1: Adalbert
person_process_field_familienname >>> fam2: <re.Match object; span=(9, 20), match='(Adelberth)'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Konzipist'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Konzipist'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Konzipist'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = NÖ-R / Konzipisten
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = NÖ-R 
process_chunks >>> cD ['1675/76-00-00<1675-06-30 - 76-00-00>', 'bis 1677<1677-06-30>'], cF ['Konzipist'], cH L, CA NÖ-R 
helper_hsv_post_process_dates >>> inner date: <1675-06-30 - 76-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> old: 1675/76-00-00<1675-06-30 - 76-00-00>, new: 1675/76-00-00<1675-06-30 - 76-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>> rel, chunk edw: 1675/76-00-00<1675-06-30 - 76-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adalbert, Adam>, 'start_date_written': '1675/76-00-00<1675-06-30 - 76-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: NÖ-R 
chunk_process_amt_NEW >>> c_A was: NÖ-R  and amt after matching with amt index is: NÖ-R
chunk_process_amt_NEW >>>  Return value of inst2 = NÖ-R (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Konzipist']

--------- Start of row | 31 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adam
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sattelknecht'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1704-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Sattelknecht'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = J
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: J
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: J
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1704-00-00'], 'HOFSTAAT': 'J', 'FUNKTION': ['Sattelknecht'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OStA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OStA
process_chunks >>> cD ['1704-00-00'], cF ['Sattelknecht'], cH J, CA OStA
helper_hsv_post_process_dates >>> old: 1704-00-00, new: 1704-00-00<1704-06-30>
chunk_process_datum >>> rel, chunk sdw: 1704-00-00<1704-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adam, Johann>, 'start_date_written': '1704-00-00<1704-06-30>'}
chunk_get_nm_hst >>> c_H = J
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: J1 (Ehzg.)
chunk_process_amt_NEW >>> c_A in if c_A true: OStA
chunk_process_amt_NEW >>> c_A was: OStA and amt after matching with amt index is: OStA
chunk_process_amt_NEW >>>  Return value of inst2 = OStA (J1 (Ehzg.))
chunk_create_relations >>> create realtions called for c_F ['Sattelknecht']

--------- Start of row | 32 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adamo
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1678-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1678-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kammerdiener'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = EM
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: EM
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: EM
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1678-00-00'], 'HOFSTAAT': 'EM', 'FUNKTION': ['Kammerdiener'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD ['1678-00-00'], cF ['Kammerdiener'], cH EM, CA Dummy Amt
helper_hsv_post_process_dates >>> old: 1678-00-00, new: 1678-00-00<1678-06-30>
chunk_process_datum >>> rel, chunk sdw: 1678-00-00<1678-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adamo, NN>, 'start_date_written': '1678-00-00<1678-06-30>'}
chunk_get_nm_hst >>> c_H = EM
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: EM (Ksin.)
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (EM (Ksin.))
chunk_create_relations >>> create realtions called for c_F ['Kammerdiener']

--------- Start of row | 33 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adimis (Attems)
person_process_field_familienname >>> fam1: Adimis
person_process_field_familienname >>> fam2: <re.Match object; span=(7, 15), match='(Attems)'>
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1686-11-15', 'bis 1687-10-27<1687-10-27>'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1686-11-15', 'bis 1687-10-27<1687-10-27>'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1686-11-15', 'bis 1687-10-27<1687-10-27>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1686-11-15', 'bis 1687-10-27<1687-10-27>'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1686-11-15, new: 1686-11-15<1686-11-15>
helper_hsv_post_process_dates >>> inner date: <1687-10-27>
helper_hsv_post_process_dates >>> new_i_date: <1687-10-27>
helper_hsv_post_process_dates >>> old: bis 1687-10-27<1687-10-27>, new: bis 1687-10-27<1687-10-27>
chunk_process_datum >>> rel, chunk sdw: 1686-11-15<1686-11-15>
chunk_process_datum >>> rel, chunk edw: 1686-11-15<1686-11-15>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adimis, Franz Andre>, 'start_date_written': '1686-11-15<1686-11-15>', 'end_date_written': 'bis 1687-10-27<1687-10-27>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 34 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adimus (Attems)
person_process_field_familienname >>> fam1: Adimus
person_process_field_familienname >>> fam2: <re.Match object; span=(7, 15), match='(Attems)'>
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1660-09-04'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1660-09-04'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1660-09-04'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1660-09-04'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1660-09-04, new: 1660-09-04<1660-09-04>
chunk_process_datum >>> rel, chunk sdw: 1660-09-04<1660-09-04>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adimus, Hanns Jacob>, 'start_date_written': '1660-09-04<1660-09-04>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 35 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adler
person_process_field_titel >>> t_tit = Edler
person_process_field_titel >>> t_list = ['Edler']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1674-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Reichshofrat'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1674-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Reichshofrat'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1674-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Reichshofrat'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = RHR / Gelehrtenbank
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = RHR 
process_chunks >>> cD ['1674-00-00'], cF ['Reichshofrat'], cH L, CA RHR 
helper_hsv_post_process_dates >>> old: 1674-00-00, new: 1674-00-00<1674-06-30>
chunk_process_datum >>> rel, chunk sdw: 1674-00-00<1674-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adler, Franz Friedrich>, 'start_date_written': '1674-00-00<1674-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: RHR 
chunk_process_amt_NEW >>> c_A was: RHR  and amt after matching with amt index is: RHR
chunk_process_amt_NEW >>>  Return value of inst2 = RHR (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Reichshofrat']

--------- Start of row | 36 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Adler
person_process_field_titel >>> t_tit = Freiherr
person_process_field_titel >>> t_list = ['Freiherr']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> RenameFunctions.py >>> removing ? from ents
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': [], 'HOFSTAAT': None, 'FUNKTION': [], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 0
helper_hsv_match_hofstaate >>> r_H = nan
helper_hsv_match_hofstaate >>> chunk Hofstaat = Dummy Hofstaat
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': [], 'HOFSTAAT': 'Dummy Hofstaat', 'FUNKTION': [], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = nan
helper_hsv_match_amt_with_funct >>> Caught Empty or Empty Stringed Amt -> c[amt] set to = Dummy Amt
process_chunks >>> cD [], cF [], cH Dummy Hofstaat, CA Dummy Amt
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Adler, Wenzel Wallkhaun?>}
chunk_get_nm_hst >>> c_H = Dummy Hofstaat
chunk_process_amt_NEW >>> c_A in if c_A true: Dummy Amt
chunk_process_amt_NEW >>> c_A was: Dummy Amt and amt after matching with amt index is: Dummy Amt
chunk_process_amt_NEW >>>  Return value of inst2 = Dummy Amt (Dummy Hofstaat)
chunk_create_relations >>> create realtions called for c_F []

--------- Start of row | 37 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Aegani
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1669-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Hofkaplan'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1669-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Hofkaplan'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1669-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Hofkaplan'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OMeA / Hofkapelle
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OMeA 
process_chunks >>> cD ['1669-00-00'], cF ['Hofkaplan'], cH L, CA OMeA 
helper_hsv_post_process_dates >>> old: 1669-00-00, new: 1669-00-00<1669-06-30>
chunk_process_datum >>> rel, chunk sdw: 1669-00-00<1669-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Aegani, NN>, 'start_date_written': '1669-00-00<1669-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OMeA 
chunk_process_amt_NEW >>> c_A was: OMeA  and amt after matching with amt index is: OMeA
chunk_process_amt_NEW >>>  Return value of inst2 = OMeA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Hofkaplan']

--------- Start of row | 38 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Aehlen?
person_process_field_titel >>> t_tit = Graf
person_process_field_titel >>> t_list = ['Graf']
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc._excel_row was not in annotations.keys
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1676-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1676-00-00'], 'HOFSTAAT': None, 'FUNKTION': ['Kämmerer'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1676-00-00'], 'HOFSTAAT': 'L', 'FUNKTION': ['Kämmerer'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = OKäA
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = OKäA
process_chunks >>> cD ['1676-00-00'], cF ['Kämmerer'], cH L, CA OKäA
helper_hsv_post_process_dates >>> old: 1676-00-00, new: 1676-00-00<1676-06-30>
chunk_process_datum >>> rel, chunk sdw: 1676-00-00<1676-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Aehlen?, Ferdinand>, 'start_date_written': '1676-00-00<1676-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: OKäA
chunk_process_amt_NEW >>> c_A was: OKäA and amt after matching with amt index is: OKäA
chunk_process_amt_NEW >>>  Return value of inst2 = OKäA (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Kämmerer']

--------- Start of row | 39 | -------------- 
person_process_field_vorname >>> r_vor
person_process_field_familienname >>> Agradin (Agredin)
person_process_field_familienname >>> fam1: Agradin
person_process_field_familienname >>> fam2: <re.Match object; span=(8, 17), match='(Agredin)'>
NLP COMPONENT >>> UseExistingAnnotations.py >>> Entered call
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc.ents at start of call = (Raitrat, Buchhalter/Raitrat, Expeditor, 1672/73-00-00, 1677-00-00)
NLP COMPONENT >>> UseExistingAnnotations.py >>> compare docs
NLP COMPONENT >>> UseExistingAnnotations.py >>> THIS WAS LOGGED :39, Raitrat / Buchhalter/Raitrat(?) / Expeditor (1672/73-00-00 bis 1677-00-00), [{'start': 0, 'end': 7, 'token_start': 0, 'token_end': 0, 'label': 'FUNKTION'}, {'start': 10, 'end': 28, 'token_start': 2, 'token_end': 4, 'label': 'FUNKTION'}, {'start': 34, 'end': 43, 'token_start': 9, 'token_end': 9, 'label': 'FUNKTION'}, {'start': 45, 'end': 58, 'token_start': 11, 'token_end': 17, 'label': 'DATUM'}, {'start': 63, 'end': 73, 'token_start': 19, 'token_end': 23, 'label': 'DATUM'}]
NLP COMPONENT >>> UseExistingAnnotations.py >>> lst_ents = [Raitrat, Buchhalter/Raitrat, Expeditor, 1672/73-00-00, 1677-00-00]
NLP COMPONENT >>> UseExistingAnnotations.py >>> doc.ents at end of call = (Raitrat, Buchhalter/Raitrat, Expeditor, 1672/73-00-00, 1677-00-00)
NLP COMPONENT >>> CreateChunks.py >>> this was finally written, chunk(1) = [{'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Raitrat', 'Buchhalter/Raitrat', 'Expeditor'], 'AMT': None}]
NLP COMPONENT >>> CreateChunks.py >>> 	0: chunk: {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': None, 'FUNKTION': ['Raitrat', 'Buchhalter/Raitrat', 'Expeditor'], 'AMT': None}
process_chunks >>> len_doc_chunks: 1, len Ämter-Spalte: 1
helper_hsv_match_hofstaate >>> r_H = L
helper_hsv_match_hofstaate >>> HOFSTAATE PROCESSING ----> h: L
helper_hsv_match_hofstaate >>> NO CHUNK HOFSTAAT
helper_hsv_match_hofstaate >>> chunk Hofstaat set to: L
helper_hsv_match_hofstaate >>> chunk is -- > {'DATUM': ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1677<1677-06-30>'], 'HOFSTAAT': 'L', 'FUNKTION': ['Raitrat', 'Buchhalter/Raitrat', 'Expeditor'], 'AMT': None}
helper_hsv_match_amt_with_funct >>> r_A = HK-NÖ-BH
helper_hsv_match_amt_with_funct >>> r_A equals len(Chunks) -> c[amt] = HK-NÖ-BH
process_chunks >>> cD ['1672/73-00-00<1672-06-30 - 73-00-00>', 'bis 1677<1677-06-30>'], cF ['Raitrat', 'Buchhalter/Raitrat', 'Expeditor'], cH L, CA HK-NÖ-BH
helper_hsv_post_process_dates >>> inner date: <1672-06-30 - 73-00-00>
helper_hsv_post_process_dates >>> new_i_date: <1672-06-30 - 73-06-30>
helper_hsv_post_process_dates >>> old: 1672/73-00-00<1672-06-30 - 73-00-00>, new: 1672/73-00-00<1672-06-30 - 73-06-30>
helper_hsv_post_process_dates >>> inner date: <1677-06-30>
helper_hsv_post_process_dates >>> new_i_date: <1677-06-30>
helper_hsv_post_process_dates >>> old: bis 1677<1677-06-30>, new: bis 1677<1677-06-30>
chunk_process_datum >>> rel, chunk sdw: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>> rel, chunk edw: 1672/73-00-00<1672-06-30 - 73-06-30>
chunk_process_datum >>>  this is the full relation: {'related_person': <Person: Agradin, Christoph>, 'start_date_written': '1672/73-00-00<1672-06-30 - 73-06-30>', 'end_date_written': 'bis 1677<1677-06-30>'}
chunk_get_nm_hst >>> c_H = L
chunk_create_institution >>> nm_hst is not Dummy Hofstaat: L1 (Ks.)
chunk_process_amt_NEW >>> c_A in if c_A true: HK-NÖ-BH
chunk_process_amt_NEW >>> c_A was: HK-NÖ-BH and amt after matching with amt index is: HK-NÖ-BH
chunk_process_amt_NEW >>>  Return value of inst2 = HK-NÖ-BH (L1 (Ks.))
chunk_create_relations >>> create realtions called for c_F ['Raitrat', 'Buchhalter/Raitrat', 'Expeditor']
